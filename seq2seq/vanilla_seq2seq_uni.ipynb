{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "vanilla_seq2seq-uni.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlKNUMdevLKx"
      },
      "source": [
        "# **Implement Seq2Seq from scratch**\n",
        "\n",
        "---\n",
        "Model: Seq2Seq Uni-GRU without Attention\n",
        "\n",
        "Dataset: Huggingface's mt_en_vi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeiIMowK0f-z"
      },
      "source": [
        "### Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CctiDb0bvWoK"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIIr1OxLkMpp"
      },
      "source": [
        "class RNNEncoder(nn.Module):\n",
        "    def __init__(self, source_vocab_size, emb_size=300, hidden_size=1024, num_layers=2, dropout_ratio=0.2, bidirectional=True):\n",
        "        super().__init__()\n",
        "        self.src_vocab_size = source_vocab_size\n",
        "        self.hidden_size = hidden_size // 2 if bidirectional else hidden_size\n",
        "        self.n_layers = num_layers\n",
        "        self.n_directions = 2 if bidirectional else 1\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_ratio)\n",
        "        self.embedding = nn.Embedding(num_embeddings=source_vocab_size, embedding_dim=emb_size)\n",
        "        self.gru = nn.GRU(input_size=emb_size, hidden_size=self.hidden_size, num_layers=num_layers,\n",
        "                          bidirectional=bidirectional, dropout=dropout_ratio)\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        # inputs: [max_input_length, bs]\n",
        "\n",
        "        emb = self.dropout(self.embedding(inputs))\n",
        "        out, hid = self.gru(emb)\n",
        "\n",
        "        if self.n_directions == 2:\n",
        "            hid = hid.view(self.n_layers, self.n_directions, -1, self.hidden_size)\n",
        "            hid = torch.cat((hid[:, 0, :, :], hid[:, 1, :, :]), dim=2)\n",
        "        \n",
        "        return hid\n",
        "\n",
        "    def load_pretrained_embedding(self):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaFHX-vxyYby"
      },
      "source": [
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, target_vocab_size, emb_size=300, hidden_size=1024, num_layers=2, dropout_ratio=0.2):\n",
        "        super().__init__()\n",
        "        self.trg_vocab_size = target_vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = num_layers\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_ratio)\n",
        "        self.embedding = nn.Embedding(num_embeddings=target_vocab_size, embedding_dim=emb_size)\n",
        "        self.gru = nn.GRU(input_size=emb_size, hidden_size=hidden_size, \n",
        "                          num_layers=num_layers, dropout=dropout_ratio)\n",
        "        self.fc = nn.Linear(in_features=hidden_size, out_features=target_vocab_size)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        input = input.unsqueeze(0)\n",
        "        # input: [1, bs]\n",
        "\n",
        "        emb = self.dropout(self.embedding(input))\n",
        "        out, hid = self.gru(emb, hidden)\n",
        "        \n",
        "        pred = self.fc(out.squeeze(0))\n",
        "        # pred: [bs, target_vocab_size]\n",
        "\n",
        "        return pred, hid\n",
        "\n",
        "    def load_pretrained_embedding(self):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wnAmsPODnZh"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.bidirectional_encoder = True if encoder.n_directions == 2 else False\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0):\n",
        "        \n",
        "        # src: [max_input_length, bs]\n",
        "        # trg: [max_output_length, bs]\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        max_output_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.trg_vocab_size\n",
        "        \n",
        "        # tensor to store decoder outputs\n",
        "        preds = torch.zeros(max_output_len, batch_size, trg_vocab_size).to(DEVICE)\n",
        "    \n",
        "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden = self.encoder(src)\n",
        "                \n",
        "        # first input to the decoder is the <sos> tokens\n",
        "        input = trg[0]\n",
        "        \n",
        "        for t in range(1, max_output_len):         \n",
        "            pred, hidden = self.decoder(input, hidden)\n",
        "            preds[t] = pred\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            best_pred = pred.argmax(1) \n",
        "            input = trg[t] if teacher_force else best_pred\n",
        "        \n",
        "        return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzUl0df3URG2"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLnSrJwXUV7B"
      },
      "source": [
        "Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaOJF4aG_1Vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec7b866-04ec-4aa0-b362-3095157dedf0"
      },
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "hf_dataset = load_dataset('mt_eng_vietnamese', 'iwslt2015-vi-en')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: huggingface-hub==0.0.2 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.4.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.2->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset mt_eng_vietnamese (/root/.cache/huggingface/datasets/mt_eng_vietnamese/iwslt2015-vi-en/1.0.0/87223258c122f5f4a9bee0428064f4b49a9463fad8177a3b03c0615e4f3122b7)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4tkbv8Bardf"
      },
      "source": [
        "Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDGElkdZovqn",
        "outputId": "03644f68-388a-485c-e8de-9bfd2ebdaf49"
      },
      "source": [
        "# Import hf's tokenizer\n",
        "!pip install transformers\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq1Bm17io07R"
      },
      "source": [
        "# Create iterator through a data set. Convert text into tensors\n",
        "# Returns list of batches, each batch: {'src': [max_input_length, bs], 'trg': [max_output_length, bs]}\n",
        "\n",
        "def make_iterator(dataset, batch_size):\n",
        "    n_examples = len(dataset)\n",
        "    random.shuffle(dataset)\n",
        "    iterator = []\n",
        "    for i in range(n_examples // batch_size):\n",
        "        src_texts = []\n",
        "        trg_texts = []\n",
        "        for j in range(batch_size):\n",
        "            src_texts.append(dataset[batch_size*i+j]['en'])\n",
        "            trg_texts.append(dataset[batch_size*i+j]['vi'])\n",
        "        src_tensors = tokenizer(src_texts, padding='max_length', max_length=MAX_INPUT_LENGTH, truncation=True, return_tensors='pt')['input_ids'].permute(1, 0)\n",
        "        trg_tensors = tokenizer(trg_texts, padding='max_length', max_length=MAX_OUTPUT_LENGTH, truncation=True, return_tensors='pt')['input_ids'].permute(1, 0)\n",
        "        new_batch = {'src': src_tensors, 'trg': trg_tensors}\n",
        "        iterator.append(new_batch)\n",
        "    return iterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxnLPi7RavZ1"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gewChWUCbk5N"
      },
      "source": [
        "def train(model, iterator, criterion, optimizer):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch['src'].to(DEVICE)\n",
        "        trg = batch['trg'].to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg, TEACHER_FORCING_RATIO)\n",
        "\n",
        "        \n",
        "        # src: [max_input_length, bs]\n",
        "        # trg: [max_output_length, bs]\n",
        "        # output: [max_output_length, bs, trg_vocab_size]\n",
        "        \n",
        "        trg_vocab_size = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].reshape(-1, trg_vocab_size)\n",
        "        trg = trg[1:].reshape(-1)\n",
        "        \n",
        "        # trg = [(trg len - 1) * batch size]\n",
        "        # output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "                \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smSl7Rnab9FC"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch['src'].to(DEVICE)\n",
        "            trg = batch['trg'].to(DEVICE)\n",
        "\n",
        "            output = model(src, trg)\n",
        "\n",
        "            # src: [max_input_length, bs]\n",
        "            # trg: [max_output_length, bs]\n",
        "            # output: [max_output_length, bs, trg_vocab_size]\n",
        "            \n",
        "            trg_vocab_size = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].reshape(-1, trg_vocab_size)\n",
        "            trg = trg[1:].reshape(-1)\n",
        "            \n",
        "            # trg = [(trg len - 1) * batch size]\n",
        "            # output = [(trg len - 1) * batch size, output dim]\n",
        "            \n",
        "            loss = criterion(output, trg)            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWmW_YWLKB3I"
      },
      "source": [
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgyCrQWejy-g"
      },
      "source": [
        "# Training hyperparams\n",
        "BATCH_SIZE = 128\n",
        "MAX_INPUT_LENGTH = 32\n",
        "MAX_OUTPUT_LENGTH = 64\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 0.0005\n",
        "TEACHER_FORCING_RATIO = 0.2\n",
        "\n",
        "# Model hyperparams\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "VOCAB_SIZE = tokenizer.vocab_size\n",
        "encoder = RNNEncoder(VOCAB_SIZE, bidirectional=False).to(DEVICE)\n",
        "decoder = RNNDecoder(VOCAB_SIZE).to(DEVICE)\n",
        "seq2seq = Seq2Seq(encoder, decoder).to(DEVICE)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=0)     # ignore [PAD] token\n",
        "optim = torch.optim.Adam(seq2seq.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy89h3IcoHGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ccd7b4-5157-43e0-9763-31d50afa6b9e"
      },
      "source": [
        "# Train model and save the best checkpoint\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "    # Generate train_iterator, valid_iterator\n",
        "    train_iterator = make_iterator(hf_dataset['train'][:]['translation'], BATCH_SIZE)\n",
        "    valid_iterator = make_iterator(hf_dataset['validation'][:]['translation'], BATCH_SIZE)\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(seq2seq, train_iterator, loss_function, optim)\n",
        "    valid_loss = evaluate(seq2seq, valid_iterator, loss_function)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(seq2seq.state_dict(), 'vanilla-seq2seq.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 29m 16s\n",
            "\tTrain Loss: 4.300\n",
            "\t Val. Loss: 4.288\n",
            "Epoch: 02 | Time: 29m 24s\n",
            "\tTrain Loss: 3.920\n",
            "\t Val. Loss: 4.240\n",
            "Epoch: 03 | Time: 29m 32s\n",
            "\tTrain Loss: 3.780\n",
            "\t Val. Loss: 4.165\n",
            "Epoch: 04 | Time: 29m 33s\n",
            "\tTrain Loss: 3.693\n",
            "\t Val. Loss: 4.110\n",
            "Epoch: 05 | Time: 29m 36s\n",
            "\tTrain Loss: 3.610\n",
            "\t Val. Loss: 4.111\n",
            "Epoch: 06 | Time: 29m 37s\n",
            "\tTrain Loss: 3.575\n",
            "\t Val. Loss: 4.059\n",
            "Epoch: 07 | Time: 29m 33s\n",
            "\tTrain Loss: 3.531\n",
            "\t Val. Loss: 4.041\n",
            "Epoch: 08 | Time: 29m 36s\n",
            "\tTrain Loss: 3.478\n",
            "\t Val. Loss: 4.059\n",
            "Epoch: 09 | Time: 29m 28s\n",
            "\tTrain Loss: 3.446\n",
            "\t Val. Loss: 4.019\n",
            "Epoch: 10 | Time: 29m 27s\n",
            "\tTrain Loss: 3.411\n",
            "\t Val. Loss: 4.059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJnuEqPiqgAn"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NExq9i8ON7Az",
        "outputId": "54b2a23e-52b5-4470-9deb-6d9deac3cd7c"
      },
      "source": [
        "# Compute loss on test set\n",
        "seq2seq.load_state_dict(torch.load('vanilla-seq2seq.pt'))\n",
        "test_iterator = make_iterator(hf_dataset['test'][:]['translation'], BATCH_SIZE)\n",
        "test_loss = evaluate(seq2seq, test_iterator, loss_function)\n",
        "print(f'\\tTest Loss: {test_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTest Loss: 4.054\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}