{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "r_tKcoYzazFZ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlKNUMdevLKx"
      },
      "source": [
        "**Implement Seq2Seq from scratch**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeiIMowK0f-z"
      },
      "source": [
        "### Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CctiDb0bvWoK"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIIr1OxLkMpp"
      },
      "source": [
        "class RNNEncoder(nn.Module):\n",
        "    def __init__(self, source_vocab_size, emb_size=300, hidden_size=1024, num_layers=2, dropout_ratio=0.2, bidirectional=True):\n",
        "        super().__init__()\n",
        "        pass\n",
        "    \n",
        "    def forward(self):\n",
        "        pass\n",
        "\n",
        "    def load_pretrained_embedding(self):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaFHX-vxyYby"
      },
      "source": [
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, target_vocab_size, emb_size=300, hidden_size=1024, num_layers=2, dropout_ratio=0.2):\n",
        "        super().__init__()\n",
        "        pass\n",
        "    \n",
        "    def forward(self):\n",
        "        pass\n",
        "\n",
        "    def load_pretrained_embedding(self):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2GCK9E6IJ29"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzUl0df3URG2"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLnSrJwXUV7B"
      },
      "source": [
        "Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaOJF4aG_1Vm"
      },
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset('mt_eng_vietnamese')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPlRtUz2BhZe"
      },
      "source": [
        "Create vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bGtCrXPAPjK"
      },
      "source": [
        "PAD_token = 0\n",
        "BOS_token = 1\n",
        "EOS_token = 2\n",
        "UNK_token = 3\n",
        "class Lang:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Convert between token, index and tensor\n",
        "        \"\"\"\n",
        "        self.token2index = {'<pad>': 0, '<bos>': 1, '<eos>': 2, '<unk>': 3}\n",
        "        self.index2token = {0: '<pad>', 1: '<bos>', 2: '<eos>', 3: '<unk>'}\n",
        "        self.vocab_len = 4\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if tok not in self.token2index:\n",
        "            self.token2index[tok] = self.vocab_len\n",
        "            self.index2tok[self.vocab_len] = tok\n",
        "            self.vocab_len += 1\n",
        "\n",
        "    def sentence_to_tensor(self, sen):\n",
        "        pass\n",
        "\n",
        "    def tensor_to_sentence(self, tensor):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf1plHZoIDzJ"
      },
      "source": [
        "# Import tokenizer, vectorizer\n",
        "# Tokenize, vectorize (optional)\n",
        "# Create source and target vocab \n",
        "# Add tokens into vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4tkbv8Bardf"
      },
      "source": [
        "Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD9eyKiUnC8_"
      },
      "source": [
        "def pad(doc):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9XMdGKnD4Ne"
      },
      "source": [
        "# Clean data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxnLPi7RavZ1"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gewChWUCbk5N"
      },
      "source": [
        "def train():\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgyCrQWejy-g"
      },
      "source": [
        "# Training hyperparam\n",
        "NUM_EPOCHS = 50\n",
        "LEARNING_RATE = 0.0001\n",
        "BATCH_SIZE = 16\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "loss_function = nn.NLLLoss(ignore_index=0)\n",
        "optim = torch.optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Model hyperparam\n",
        "VOCAB_SIZE = len(eng_vocab.word2index)\n",
        "encoder = RNNEncoder(vocab_size=VOCAB_SIZE).to(DEVICE)\n",
        "decoder = RNNDecoder(vocab_size=VOCAB_SIZE).to(DEVICE)\n",
        "seq2seq = Seq2Seq(encoder, decoder).to(DEVICE)\n",
        "\n",
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy89h3IcoHGk"
      },
      "source": [
        "# Save weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_tKcoYzazFZ"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exiqy_0ecK51"
      },
      "source": [
        "Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wECE9GXmsajQ"
      },
      "source": [
        "# Load model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyOdAgEBpm9h"
      },
      "source": [
        "# Test output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ThpqN4CcB9j"
      },
      "source": [
        "Evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smSl7Rnab9FC"
      },
      "source": [
        "def evaluate():\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}